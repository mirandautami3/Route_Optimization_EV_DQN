{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Data Preparation\n",
    "#‚úî Mengambil data jaringan jalan dari OSM untuk Jawa Timur\n",
    "#‚úî Memuat data SPKLU dari CSV\n",
    "#‚úî Membangun graf jaringan jalan dengan bobot jarak dan konsumsi energi\n",
    "#‚úî Menyimpan graf untuk dipakai di tahap selanjutnya\n",
    "\n",
    "#Step 1: Import Library yang Dibutuhkan\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Tentukan Daftar Kota yang Akan Diproses\n",
    "cities = [\"Surabaya, Indonesia\", \"Malang, Indonesia\", \"Kediri, Indonesia\", \"Sidoarjo, Indonesia\", \"Gresik, Indonesia\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Memuat data SPKLU dari CSV...\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Baca Data SPKLU dari CSV\n",
    "print(\"üìå Memuat data SPKLU dari CSV...\")\n",
    "spklu_df = pd.read_csv(\"../data/spklu_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Memproses kota: Surabaya, Indonesia...\n",
      "\n",
      "üîπ Memproses kota: Malang, Indonesia...\n",
      "\n",
      "üîπ Memproses kota: Kediri, Indonesia...\n",
      "\n",
      "üîπ Memproses kota: Sidoarjo, Indonesia...\n",
      "\n",
      "üîπ Memproses kota: Gresik, Indonesia...\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Looping untuk Setiap Kota\n",
    "for city_name in cities:\n",
    "    print(f\"\\nüîπ Memproses kota: {city_name}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data jalan Surabaya, Indonesia sudah tersedia, menggunakan data yang disimpan...\n",
      "‚úÖ Data jalan Malang, Indonesia sudah tersedia, menggunakan data yang disimpan...\n",
      "‚úÖ Data jalan Kediri, Indonesia sudah tersedia, menggunakan data yang disimpan...\n",
      "‚úÖ Data jalan Sidoarjo, Indonesia sudah tersedia, menggunakan data yang disimpan...\n",
      "‚úÖ Data jalan Gresik, Indonesia sudah tersedia, menggunakan data yang disimpan...\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Cek Apakah Data Jalan Sudah Ada\n",
    "import os\n",
    "\n",
    "# Daftar kota yang akan diambil datanya\n",
    "cities = [\"Surabaya, Indonesia\", \"Malang, Indonesia\", \"Kediri, Indonesia\", \n",
    "          \"Sidoarjo, Indonesia\", \"Gresik, Indonesia\"]\n",
    "\n",
    "for city_name in cities:\n",
    "    safe_city_name = city_name.split(\",\")[0].replace(\" \", \"_\").lower()  # Format nama aman untuk file\n",
    "    road_graph_path = f\"../data/road_graph_{safe_city_name}.pkl\"\n",
    "\n",
    "    if os.path.exists(road_graph_path):\n",
    "        print(f\"‚úÖ Data jalan {city_name} sudah tersedia, menggunakan data yang disimpan...\")\n",
    "    else:\n",
    "        print(f\"üìå Mengambil data jaringan jalan di {city_name}...\")\n",
    "        road_graph = ox.graph_from_place(city_name, network_type=\"drive\", simplify=True)\n",
    "        nx.write_gpickle(road_graph, road_graph_path)\n",
    "        print(f\"‚úÖ Data jalan {city_name} berhasil disimpan.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Menambahkan SPKLU ke dalam graf jalan...\n",
      "‚úÖ Menggunakan data jalan yang sudah ada untuk Surabaya, Indonesia...\n",
      "üìå Memproses SPKLU di Surabaya, Indonesia...\n",
      "‚úÖ Menggunakan data jalan yang sudah ada untuk Malang, Indonesia...\n",
      "üìå Memproses SPKLU di Malang, Indonesia...\n",
      "‚ö†Ô∏è Tidak ada SPKLU untuk Malang, Indonesia, melewati...\n",
      "‚úÖ Menggunakan data jalan yang sudah ada untuk Kediri, Indonesia...\n",
      "üìå Memproses SPKLU di Kediri, Indonesia...\n",
      "‚ö†Ô∏è Tidak ada SPKLU untuk Kediri, Indonesia, melewati...\n",
      "‚úÖ Menggunakan data jalan yang sudah ada untuk Sidoarjo, Indonesia...\n",
      "üìå Memproses SPKLU di Sidoarjo, Indonesia...\n",
      "‚ö†Ô∏è Tidak ada SPKLU untuk Sidoarjo, Indonesia, melewati...\n",
      "‚úÖ Menggunakan data jalan yang sudah ada untuk Gresik, Indonesia...\n",
      "üìå Memproses SPKLU di Gresik, Indonesia...\n",
      "‚ö†Ô∏è Tidak ada SPKLU untuk Gresik, Indonesia, melewati...\n",
      "‚úÖ Total SPKLU yang berhasil dimasukkan ke dalam graf: 9\n"
     ]
    }
   ],
   "source": [
    "#Step 6: Tambahkan SPKLU ke Graf Jalan\n",
    "\n",
    "# Daftar kota yang akan diambil datanya\n",
    "cities = [\"Surabaya, Indonesia\", \"Malang, Indonesia\", \"Kediri, Indonesia\", \n",
    "          \"Sidoarjo, Indonesia\", \"Gresik, Indonesia\"]\n",
    "\n",
    "print(\"üìå Menambahkan SPKLU ke dalam graf jalan...\")\n",
    "spklu_nodes = {}\n",
    "\n",
    "for city_name in cities:\n",
    "    safe_city_name = city_name.split(\",\")[0].replace(\" \", \"_\").lower()  # Format nama aman untuk file\n",
    "    road_graph_path = f\"../data/road_graph_{safe_city_name}.pkl\"\n",
    "\n",
    "    # Load road graph jika tersedia\n",
    "    if os.path.exists(road_graph_path):\n",
    "        print(f\"‚úÖ Menggunakan data jalan yang sudah ada untuk {city_name}...\")\n",
    "        road_graph = nx.read_gpickle(road_graph_path)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Data jalan untuk {city_name} tidak ditemukan, melewati kota ini...\")\n",
    "        continue  # Skip kota jika data jalan tidak tersedia\n",
    "\n",
    "    print(f\"üìå Memproses SPKLU di {city_name}...\")\n",
    "\n",
    "    # Ambil hanya SPKLU yang sesuai dengan kota saat ini\n",
    "    city_spklu_df = spklu_df[spklu_df['Alamat'].str.contains(city_name.split(\",\")[0], case=False, na=False)]\n",
    "\n",
    "    if city_spklu_df.empty:\n",
    "        print(f\"‚ö†Ô∏è Tidak ada SPKLU untuk {city_name}, melewati...\")\n",
    "        continue\n",
    "\n",
    "    for idx, row in city_spklu_df.iterrows():\n",
    "        try:\n",
    "            nearest_node = ox.nearest_nodes(road_graph, row[\"Longitude\"], row[\"Latitude\"])\n",
    "            spklu_nodes[nearest_node] = (row[\"Latitude\"], row[\"Longitude\"])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error menambahkan SPKLU {row['Latitude']}, {row['Longitude']} di {city_name}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Total SPKLU yang berhasil dimasukkan ke dalam graf: {len(spklu_nodes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Menambahkan bobot jarak dan konsumsi energi ke graf jalan...\n",
      "‚úÖ Memproses bobot untuk Surabaya, Indonesia...\n",
      "‚úÖ Graf dengan bobot disimpan: ../data/road_graph_weighted_surabaya.pkl\n",
      "‚úÖ Memproses bobot untuk Malang, Indonesia...\n",
      "‚úÖ Graf dengan bobot disimpan: ../data/road_graph_weighted_malang.pkl\n",
      "‚úÖ Memproses bobot untuk Kediri, Indonesia...\n",
      "‚úÖ Graf dengan bobot disimpan: ../data/road_graph_weighted_kediri.pkl\n",
      "‚úÖ Memproses bobot untuk Sidoarjo, Indonesia...\n",
      "‚úÖ Graf dengan bobot disimpan: ../data/road_graph_weighted_sidoarjo.pkl\n",
      "‚úÖ Memproses bobot untuk Gresik, Indonesia...\n",
      "‚úÖ Graf dengan bobot disimpan: ../data/road_graph_weighted_gresik.pkl\n",
      "üéØ Semua graf telah diperbarui dengan bobot jarak dan konsumsi energi!\n"
     ]
    }
   ],
   "source": [
    "# # # Step 7: Tambahkan Bobot Jarak dan Konsumsi Energi ke Graf Jalan\n",
    "# #‚úî Menyimpan graf untuk dipakai di tahap selanjutnya\n",
    "\n",
    "def calculate_energy_consumption(length, inclination):\n",
    "    \"\"\"\n",
    "    Fungsi untuk menghitung konsumsi energi berdasarkan panjang jalan dan elevasi.\n",
    "    \"\"\"\n",
    "    base_consumption = 0.2  # Konsumsi dasar (kWh/km)\n",
    "    elevation_factor = 0.05  # Faktor elevasi (kWh/km per derajat kemiringan)\n",
    "    \n",
    "    return base_consumption * length + elevation_factor * (length * inclination)\n",
    "\n",
    "print(\"üìå Menambahkan bobot jarak dan konsumsi energi ke graf jalan...\")\n",
    "\n",
    "for city_name in cities:\n",
    "    safe_city_name = city_name.split(\",\")[0].replace(\" \", \"_\").lower()\n",
    "    road_graph_path = f\"../data/road_graph_{safe_city_name}.pkl\"\n",
    "    \n",
    "    if os.path.exists(road_graph_path):\n",
    "        print(f\"‚úÖ Memproses bobot untuk {city_name}...\")\n",
    "        road_graph = nx.read_gpickle(road_graph_path)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Data jalan untuk {city_name} tidak ditemukan, melewati...\")\n",
    "        continue\n",
    "\n",
    "    # Tambahkan bobot pada setiap edge\n",
    "    for u, v, data in road_graph.edges(data=True):\n",
    "        length = data.get(\"length\", 1) / 1000  # Konversi ke km\n",
    "        inclination = data.get(\"grade\", 0)  # Kemiringan jalan\n",
    "        \n",
    "        energy_consumption = calculate_energy_consumption(length, inclination)\n",
    "        \n",
    "        data[\"energy\"] = energy_consumption\n",
    "\n",
    "    # Simpan graf yang telah diperbarui\n",
    "    updated_graph_path = f\"../data/road_graph_weighted_{safe_city_name}.pkl\"\n",
    "    nx.write_gpickle(road_graph, updated_graph_path)\n",
    "    print(f\"‚úÖ Graf dengan bobot disimpan: {updated_graph_path}\")\n",
    "\n",
    "print(\"üéØ Semua graf telah diperbarui dengan bobot jarak dan konsumsi energi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2Ô∏è‚É£ Membangun Environment untuk RL\n",
    "# üîπ Langkah-langkah dalam Membangun Environment RL\n",
    "# 1Ô∏è‚É£ Merepresentasikan State (lokasi kendaraan, sisa baterai, tujuan, jenis konektor, kapsitas betrai)\n",
    "# 2Ô∏è‚É£ Mendefinisikan Action Space (bergerak ke node lain, isi baterai, dll.)\n",
    "# 3Ô∏è‚É£ Membuat Reward Function (memilih rute optimal berdasarkan jarak & konsumsi energi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ 1. Representasi State\n",
    "class EVState:\n",
    "    def __init__(self, location, battery, destination, connector_type, capacity_kwh):\n",
    "        self.location = location\n",
    "        self.battery = battery  # dalam persentase (%)\n",
    "        self.destination = destination\n",
    "        self.connector_type = connector_type\n",
    "        self.capacity_kwh = capacity_kwh  # kapasitas baterai total (kWh)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EVState(Location: {self.location}, Battery: {self.battery}%, Destination: {self.destination}, Connector: {self.connector_type})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ 2. Mendefinisikan Action Space\n",
    "class EVAction:\n",
    "    MOVE = \"move\"\n",
    "    CHARGE = \"charge\"\n",
    "\n",
    "# ‚úÖ 3. Environment dan Reward Function\n",
    "class EVEnvironment:\n",
    "    def __init__(self, road_graph, spklu_nodes):\n",
    "        self.road_graph = road_graph\n",
    "        self.spklu_nodes = spklu_nodes\n",
    "\n",
    "    def reset(self):\n",
    "        # Kamu bisa sesuaikan state awal ini dengan kebutuhan simulasi\n",
    "        self.initial_state = EVState(location=12345, battery=50, destination=67890,\n",
    "                                     connector_type=\"CCS2\", capacity_kwh=50)\n",
    "        return self.initial_state\n",
    "\n",
    "    def get_available_actions(self, state):\n",
    "        actions = []\n",
    "        if state.battery > 20:\n",
    "            neighbors = list(self.road_graph.get(state.location, {}).keys())\n",
    "            for neighbor in neighbors:\n",
    "                actions.append((EVAction.MOVE, neighbor))\n",
    "        if state.location in self.spklu_nodes:\n",
    "            actions.append((EVAction.CHARGE, state.location))\n",
    "        return actions\n",
    "\n",
    "    def get_reward(self, state, action):\n",
    "        print(f\"\\nüìå Debug: Lokasi saat ini = {state.location}, Aksi = {action}\")\n",
    "\n",
    "        if action[0] == EVAction.MOVE:\n",
    "            next_node = action[1]\n",
    "\n",
    "            if state.location in self.road_graph and next_node in self.road_graph[state.location]:\n",
    "                edge_data = self.road_graph[state.location][next_node]\n",
    "                print(f\"üîç Debug: Data edge dari {state.location} ke {next_node} = {edge_data}\")\n",
    "\n",
    "                distance = edge_data.get(\"distance\")\n",
    "                energy_used = edge_data.get(\"energy\")\n",
    "\n",
    "                if distance is None or energy_used is None:\n",
    "                    return -5  # Penalti jika data tidak lengkap\n",
    "\n",
    "                if state.battery < energy_used * 100:\n",
    "                    print(\"‚ö†Ô∏è Warning: Energi tidak cukup untuk mencapai node tujuan.\")\n",
    "                    return -15\n",
    "\n",
    "                progress_reward = max(5 - distance / 1000, 0)\n",
    "                energy_penalty = -energy_used\n",
    "                return progress_reward + energy_penalty\n",
    "            else:\n",
    "                print(f\"üö® Error: Lokasi {state.location} atau tujuan {next_node} tidak valid!\")\n",
    "                return -10\n",
    "\n",
    "        elif action[0] == EVAction.CHARGE:\n",
    "            if action[1] in self.spklu_nodes:\n",
    "                if state.battery >= 95:\n",
    "                    return -2  # Penalti kecil karena overcharge\n",
    "                return 5\n",
    "            else:\n",
    "                return -5\n",
    "\n",
    "        return -1  # Penalti default untuk aksi tidak dikenal\n",
    "\n",
    "    def step(self, state, action):\n",
    "        reward = self.get_reward(state, action)\n",
    "        done = False\n",
    "\n",
    "        if action[0] == EVAction.MOVE:\n",
    "            next_node = action[1]\n",
    "            edge_data = self.road_graph[state.location][next_node]\n",
    "            energy_used = edge_data.get(\"energy\", 0)\n",
    "            new_battery = max(state.battery - energy_used * 100, 0)\n",
    "\n",
    "            next_state = EVState(location=next_node, battery=new_battery,\n",
    "                                 destination=state.destination,\n",
    "                                 connector_type=state.connector_type,\n",
    "                                 capacity_kwh=state.capacity_kwh)\n",
    "\n",
    "        elif action[0] == EVAction.CHARGE:\n",
    "            if state.location in self.spklu_nodes:\n",
    "                next_state = EVState(location=state.location, battery=100,\n",
    "                                     destination=state.destination,\n",
    "                                     connector_type=state.connector_type,\n",
    "                                     capacity_kwh=state.capacity_kwh)\n",
    "            else:\n",
    "                next_state = state  # gagal nge-charge\n",
    "        else:\n",
    "            next_state = state\n",
    "\n",
    "        if next_state.location == state.destination:\n",
    "            done = True\n",
    "            reward += 50  # Bonus reward sampai tujuan\n",
    "\n",
    "        return next_state, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Debug: Lokasi saat ini = 12345, Aksi = ('move', 67890)\n",
      "üîç Debug: Data edge dari 12345 ke 67890 = {'distance': 5000, 'energy': 3}\n",
      "‚ö†Ô∏è Warning: Energi tidak cukup untuk mencapai node tujuan.\n",
      "üîπ Reward MOVE: -15\n",
      "\n",
      "üìå Debug: Lokasi saat ini = 12345, Aksi = ('charge', 12345)\n",
      "üîπ Reward CHARGE: 5\n"
     ]
    }
   ],
   "source": [
    "# Contoh data graf jalan\n",
    "road_graph = {\n",
    "    12345: {67890: {\"distance\": 5000, \"energy\": 3}},\n",
    "    67890: {12345: {\"distance\": 5000, \"energy\": 3}}\n",
    "}\n",
    "\n",
    "# Lokasi SPKLU\n",
    "spklu_nodes = {12345, 67890}\n",
    "\n",
    "# Inisialisasi environment dan state awal\n",
    "env = EVEnvironment(road_graph, spklu_nodes)\n",
    "state = env.reset()\n",
    "\n",
    "# Tes aksi MOVE dan CHARGE\n",
    "action_move = (EVAction.MOVE, 67890)\n",
    "action_charge = (EVAction.CHARGE, 12345)\n",
    "\n",
    "print(\"üîπ Reward MOVE:\", env.get_reward(state, action_move))\n",
    "print(\"üîπ Reward CHARGE:\", env.get_reward(state, action_charge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ‚úÖ Tahap 3: Implementasi Model DQN\n",
    "# 1Ô∏è‚É£ Membangun Neural Network untuk memprediksi nilai ùëÑ(ùë†,ùëé)Q(s,a)\n",
    "# 2Ô∏è‚É£ Menggunakan Replay Buffer untuk menyimpan pengalaman\n",
    "# 3Ô∏è‚É£ Memanfaatkan Target Network agar pembelajaran lebih stabil\n",
    "# 4Ô∏è‚É£ Melatih model dengan strategi epsilon-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí° Tahap 3: Implementasi Model DQN ‚Äì Langkah 1: Membangun Neural Network\n",
    "# ‚úÖ 1. Membangun Model DQN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)  # Layer pertama\n",
    "        self.fc2 = nn.Linear(64, 64)          # Layer kedua\n",
    "        self.fc3 = nn.Linear(64, action_size) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # Aktivasi ReLU\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)  # Output nilai Q untuk setiap aksi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí° Tahap 3: Implementasi Model DQN ‚Äì Langkah 2: Replay Buffer\n",
    "\n",
    "# ‚úÖ 2. Implementasi Replay Buffer\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)  # Menyimpan pengalaman dalam antrian terbatas\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))  # Tambahkan pengalaman baru\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)  # Ambil sampel acak\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)  # Cek jumlah data di buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pengalaman tersimpan: 1\n",
      "Contoh sampel: [(array([12345,    50, 67890,     1,    40]), 0, -11.0, array([67890,    40, 67890,     1,    40]), False)]\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ 3. Inisialisasi Replay Buffer\n",
    "\n",
    "# üîπ Inisialisasi Replay Buffer\n",
    "replay_buffer = ReplayBuffer(capacity=10000)\n",
    "\n",
    "# üîπ Contoh pengalaman\n",
    "state = np.array([12345, 50, 67890, 1, 40])        # (location, battery, destination, connector_type, capacity_kwh)\n",
    "next_state = np.array([67890, 40, 67890, 1, 40])\n",
    "action = 0  # move\n",
    "reward = -11.0\n",
    "done = False\n",
    "\n",
    "replay_buffer.add(state, action, reward, next_state, done)\n",
    "\n",
    "# üîπ Cek\n",
    "print(f\"Total pengalaman tersimpan: {replay_buffer.size()}\")\n",
    "if replay_buffer.size() >= 1:\n",
    "    print(\"Contoh sampel:\", replay_buffer.sample(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí° Tahap 3: Implementasi Model DQN ‚Äì Langkah 3: Implementasi Target Network\n",
    "\n",
    "# üîπ Setup Model dan Target Network\n",
    "input_dim = 5  # 5 fitur dari state\n",
    "output_dim = 2  # 2 aksi: [move, charge]\n",
    "\n",
    "q_network = DQN(input_dim, output_dim)\n",
    "target_network = DQN(input_dim, output_dim)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "# üîπ Freeze parameter target network\n",
    "for param in target_network.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# üîπ Optimizer\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Update Target Network\n",
    "def update_target_network():\n",
    "    target_network.load_state_dict(q_network.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Values: tensor([-657.8627, -337.4474], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Tes Model DQN\n",
    "# Contoh input (state)\n",
    "sample_state = torch.tensor([12345, 50, 67890, 1, 50], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# üîπ Tes prediksi Q-value\n",
    "sample_state = torch.tensor([12345, 50, 67890, 1, 40], dtype=torch.float32)\n",
    "q_values = q_network(sample_state)\n",
    "print(\"Q-Values:\", q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] ‚úÖ Target network updated\n",
      "Episode 0, Epsilon: 0.995\n",
      "Episode 1, Epsilon: 0.990\n",
      "Episode 2, Epsilon: 0.985\n",
      "Episode 3, Epsilon: 0.980\n",
      "Episode 4, Epsilon: 0.975\n",
      "Episode 5, Epsilon: 0.970\n",
      "Episode 6, Epsilon: 0.966\n",
      "Episode 7, Epsilon: 0.961\n",
      "Episode 8, Epsilon: 0.956\n",
      "Episode 9, Epsilon: 0.951\n",
      "[Episode 10] ‚úÖ Target network updated\n",
      "Episode 10, Epsilon: 0.946\n",
      "Episode 11, Epsilon: 0.942\n",
      "Episode 12, Epsilon: 0.937\n",
      "Episode 13, Epsilon: 0.932\n",
      "Episode 14, Epsilon: 0.928\n",
      "Episode 15, Epsilon: 0.923\n",
      "Episode 16, Epsilon: 0.918\n",
      "Episode 17, Epsilon: 0.914\n",
      "Episode 18, Epsilon: 0.909\n",
      "Episode 19, Epsilon: 0.905\n",
      "[Episode 20] ‚úÖ Target network updated\n",
      "Episode 20, Epsilon: 0.900\n",
      "Episode 21, Epsilon: 0.896\n",
      "Episode 22, Epsilon: 0.891\n",
      "Episode 23, Epsilon: 0.887\n",
      "Episode 24, Epsilon: 0.882\n",
      "Episode 25, Epsilon: 0.878\n",
      "Episode 26, Epsilon: 0.873\n",
      "Episode 27, Epsilon: 0.869\n",
      "Episode 28, Epsilon: 0.865\n",
      "Episode 29, Epsilon: 0.860\n",
      "[Episode 30] ‚úÖ Target network updated\n",
      "Episode 30, Epsilon: 0.856\n",
      "Episode 31, Epsilon: 0.852\n",
      "Episode 32, Epsilon: 0.848\n",
      "Episode 33, Epsilon: 0.843\n",
      "Episode 34, Epsilon: 0.839\n",
      "Episode 35, Epsilon: 0.835\n",
      "Episode 36, Epsilon: 0.831\n",
      "Episode 37, Epsilon: 0.827\n",
      "Episode 38, Epsilon: 0.822\n",
      "Episode 39, Epsilon: 0.818\n",
      "[Episode 40] ‚úÖ Target network updated\n",
      "Episode 40, Epsilon: 0.814\n",
      "Episode 41, Epsilon: 0.810\n",
      "Episode 42, Epsilon: 0.806\n",
      "Episode 43, Epsilon: 0.802\n",
      "Episode 44, Epsilon: 0.798\n",
      "Episode 45, Epsilon: 0.794\n",
      "Episode 46, Epsilon: 0.790\n",
      "Episode 47, Epsilon: 0.786\n",
      "Episode 48, Epsilon: 0.782\n",
      "Episode 49, Epsilon: 0.778\n",
      "[Episode 50] ‚úÖ Target network updated\n",
      "Episode 50, Epsilon: 0.774\n",
      "Episode 51, Epsilon: 0.771\n",
      "Episode 52, Epsilon: 0.767\n",
      "Episode 53, Epsilon: 0.763\n",
      "Episode 54, Epsilon: 0.759\n",
      "Episode 55, Epsilon: 0.755\n",
      "Episode 56, Epsilon: 0.751\n",
      "Episode 57, Epsilon: 0.748\n",
      "Episode 58, Epsilon: 0.744\n",
      "Episode 59, Epsilon: 0.740\n",
      "[Episode 60] ‚úÖ Target network updated\n",
      "Episode 60, Epsilon: 0.737\n",
      "Episode 61, Epsilon: 0.733\n",
      "Episode 62, Epsilon: 0.729\n",
      "Episode 63, Epsilon: 0.726\n",
      "Episode 64, Epsilon: 0.722\n",
      "Episode 65, Epsilon: 0.718\n",
      "Episode 66, Epsilon: 0.715\n",
      "Episode 67, Epsilon: 0.711\n",
      "Episode 68, Epsilon: 0.708\n",
      "Episode 69, Epsilon: 0.704\n",
      "[Episode 70] ‚úÖ Target network updated\n",
      "Episode 70, Epsilon: 0.701\n",
      "Episode 71, Epsilon: 0.697\n",
      "Episode 72, Epsilon: 0.694\n",
      "Episode 73, Epsilon: 0.690\n",
      "Episode 74, Epsilon: 0.687\n",
      "Episode 75, Epsilon: 0.683\n",
      "Episode 76, Epsilon: 0.680\n",
      "Episode 77, Epsilon: 0.676\n",
      "Episode 78, Epsilon: 0.673\n",
      "Episode 79, Epsilon: 0.670\n",
      "[Episode 80] ‚úÖ Target network updated\n",
      "Episode 80, Epsilon: 0.666\n",
      "Episode 81, Epsilon: 0.663\n",
      "Episode 82, Epsilon: 0.660\n",
      "Episode 83, Epsilon: 0.656\n",
      "Episode 84, Epsilon: 0.653\n",
      "Episode 85, Epsilon: 0.650\n",
      "Episode 86, Epsilon: 0.647\n",
      "Episode 87, Epsilon: 0.643\n",
      "Episode 88, Epsilon: 0.640\n",
      "Episode 89, Epsilon: 0.637\n",
      "[Episode 90] ‚úÖ Target network updated\n",
      "Episode 90, Epsilon: 0.634\n",
      "Episode 91, Epsilon: 0.631\n",
      "Episode 92, Epsilon: 0.627\n",
      "Episode 93, Epsilon: 0.624\n",
      "Episode 94, Epsilon: 0.621\n",
      "Episode 95, Epsilon: 0.618\n",
      "Episode 96, Epsilon: 0.615\n",
      "Episode 97, Epsilon: 0.612\n",
      "Episode 98, Epsilon: 0.609\n",
      "Episode 99, Epsilon: 0.606\n"
     ]
    }
   ],
   "source": [
    "# 4Ô∏è‚É£ Melatih model dengan strategi epsilon-greedy\n",
    "\n",
    "\n",
    "# üîß Hyperparameter\n",
    "epsilon = 1.0           # Mulai dengan eksplorasi penuh\n",
    "epsilon_min = 0.01      # Batas bawah eksplorasi\n",
    "epsilon_decay = 0.995   # Laju penurunan epsilon per episode\n",
    "gamma = 0.99            # Discount factor\n",
    "batch_size = 32\n",
    "update_every = 10       # Update target network setiap N episode\n",
    "num_episodes = 100      # Jumlah episode latihan\n",
    "\n",
    "# üîÅ Loop utama training\n",
    "for episode in range(num_episodes):\n",
    "    # üü¢ Inisialisasi state awal (simulasi dummy)\n",
    "    state = np.array([12345, 50, 67890, 1, 40], dtype=np.float32)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # üé≤ PILIH AKSI: Epsilon-Greedy\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randint(0, 1)  # Eksplorasi\n",
    "        else:\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "            q_values = q_network(state_tensor)\n",
    "            action = torch.argmax(q_values).item()  # Eksploitasi\n",
    "\n",
    "        # üîÑ Simulasi transisi ke next_state dan reward (satu langkah saja)\n",
    "        next_state = np.array([67890, 40, 67890, 1, 40], dtype=np.float32)\n",
    "        reward = -11.0 if action == 0 else 5.0\n",
    "        done = True  # Selesai dalam satu langkah\n",
    "\n",
    "        # üíæ Simpan pengalaman ke replay buffer\n",
    "        replay_buffer.add(state, action, reward, next_state, done)\n",
    "\n",
    "        # üîÅ Update state\n",
    "        state = next_state\n",
    "\n",
    "        # üìö Training hanya jika buffer sudah cukup data\n",
    "        if replay_buffer.size() >= batch_size:\n",
    "            # Ambil sample acak dari buffer\n",
    "            batch = replay_buffer.sample(batch_size)\n",
    "            states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "            # Konversi ke tensor\n",
    "            states = torch.tensor(states, dtype=torch.float32)\n",
    "            next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "            actions = torch.tensor(actions, dtype=torch.long).unsqueeze(1)\n",
    "            rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "            # üß† Hitung Q-value prediksi dari current network\n",
    "            current_q = q_network(states).gather(1, actions)\n",
    "\n",
    "            # üéØ Hitung target Q-value dari target network\n",
    "            with torch.no_grad():\n",
    "                max_next_q = target_network(next_states).max(1, keepdim=True)[0]\n",
    "                target_q = rewards + gamma * max_next_q * (1 - dones)\n",
    "\n",
    "            # üßÆ Hitung loss dan lakukan optimisasi\n",
    "            loss = F.mse_loss(current_q, target_q)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # üìâ Kurangi epsilon (semakin lama, semakin banyak eksploitasi)\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    # üîÅ Update target network tiap beberapa episode\n",
    "    if episode % update_every == 0:\n",
    "        update_target_network()\n",
    "        print(f\"[Episode {episode}] ‚úÖ Target network updated\")\n",
    "\n",
    "    # üñ®Ô∏è Monitoring\n",
    "    print(f\"Episode {episode}, Epsilon: {epsilon:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EVALUASI HASIL =====\n",
      "Total langkah     : 1\n",
      "Total energi      : 5 kWh\n",
      "Berhasil mencapai tujuan? Ya\n",
      "\n",
      "üìç Rute yang dipilih:\n",
      "Langkah 1: State=[12345.0, 50.0, 67890.0, 1.0, 40.0] | Action=1 | Reward=5.0\n"
     ]
    }
   ],
   "source": [
    "#  ‚úÖ Tahap 4 :  Testing & Evaluasi Model\n",
    "\n",
    "# üöó Definisikan kondisi awal untuk testing\n",
    "start_node = 12345\n",
    "goal_node = 67890\n",
    "battery_level = 50      # misalnya dalam %\n",
    "connector_type = 1\n",
    "capacity = 40           # misalnya kWh\n",
    "\n",
    "initial_state = np.array([start_node, battery_level, goal_node, connector_type, capacity], dtype=np.float32)\n",
    "\n",
    "state = initial_state\n",
    "done = False\n",
    "route = []\n",
    "total_energy = 0\n",
    "step_count = 0\n",
    "\n",
    "while not done and step_count < 20:  # batasi max langkah supaya tidak infinite loop\n",
    "    state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "    q_values = q_network(state_tensor)\n",
    "    action = torch.argmax(q_values).item()\n",
    "\n",
    "    # Simulasi step (Dummy: ganti dengan fungsi asli jika sudah ada)\n",
    "    next_state = np.array([goal_node, 40, goal_node, connector_type, capacity], dtype=np.float32)\n",
    "    reward = -11.0 if action == 0 else 5.0\n",
    "    done = True if action == 1 else False\n",
    "\n",
    "    # Simpan hasil\n",
    "    route.append((state.tolist(), action, reward))\n",
    "    total_energy += 5 if action == 1 else 10  # contoh: isi daya = 5kWh, jalan = 10kWh\n",
    "    step_count += 1\n",
    "\n",
    "    # Update state\n",
    "    state = next_state\n",
    "\n",
    "# Metode evaluasi sederhana\n",
    "print(\"\\n===== EVALUASI HASIL =====\")\n",
    "print(f\"Total langkah     : {step_count}\")\n",
    "print(f\"Total energi      : {total_energy} kWh\")\n",
    "print(f\"Berhasil mencapai tujuan? {'Ya' if done else 'Tidak'}\")\n",
    "\n",
    "# Print rute\n",
    "print(\"\\nüìç Rute yang dipilih:\")\n",
    "for i, (s, a, r) in enumerate(route):\n",
    "    print(f\"Langkah {i+1}: State={s} | Action={a} | Reward={r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìê Efisiensi terhadap baseline: 13 kWh lebih hemat\n"
     ]
    }
   ],
   "source": [
    "# Misalnya kamu punya shortest_path_energy = 18\n",
    "baseline_energy = 18\n",
    "improvement = baseline_energy - total_energy\n",
    "print(f\"\\nüìê Efisiensi terhadap baseline: {improvement} kWh lebih hemat\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
